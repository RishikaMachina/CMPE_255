{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Yelp_GridSearchParameterTuning.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"6diPmdKDSlL8","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import sqlite3\n","from textblob import TextBlob\n","import spacy\n","from tqdm import tqdm\n","import pickle\n","import re\n","from sklearn import metrics\n","import scipy as sp\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import GridSearchCV\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aeXUvLxRSlMC","colab_type":"text"},"source":["## Importing the file with the raw text data for the purpose of building a Pipeline and finding the best parameters with selected Classifier"]},{"cell_type":"code","metadata":{"id":"t9mJiwj_SlMD","colab_type":"code","colab":{}},"source":["df= pickle.load(open(\"save_modifieddatabase_trainData.pkl\",\"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzFieZB0SlMG","colab_type":"code","colab":{}},"source":["df_X = df['reviewContent']\n","df_y = pickle.load(open(\"save_preprocess_trainData_labels.pkl\",\"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5315B4aNSlMK","colab_type":"code","colab":{}},"source":["text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n","text_clf = text_clf.fit(df_X, df_y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OeM42C88SlMO","colab_type":"text"},"source":["## Description of Parameters in the code below \n","\n","vect__ngram_range: [(1, 1), (1, 2)] - To Decide whether to go with Unigram or Bigram approach. For the record tried Trigram also but it didnot yieled good results, so inorder to make the code run faster for the final selction it has been removed from the hyperparameters mentioned below.\n","n_jobs=-1:This is used for parallel processing in the case of heavy computation, so as to decrease the total execution time"]},{"cell_type":"code","metadata":{"id":"BF7l9XSCSlMP","colab_type":"code","outputId":"0e7be609-b952-4bd2-fc0a-a0a2371d4840","colab":{}},"source":["parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}\n","gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1) \n","gs_clf = gs_clf.fit(df_X, df_y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/Users/neha/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zjr5VSleSlMW","colab_type":"code","outputId":"6e8e4cfc-1d58-46ac-c0b0-f85b82098a37","colab":{}},"source":["print(\"Grid Search Best Score: \",gs_clf.best_score_)\n","print(\"Grid Search Best Parameters: \",gs_clf.best_params_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Grid Search Best Score:  0.679635279596924\n","Grid Search Best Parameters:  {'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vPvouzTHSlMZ","colab_type":"code","outputId":"6c50b74f-837b-4c56-c554-8c50132e6f97","colab":{}},"source":["from sklearn.externals import joblib\n","joblib.dump(gs_clf, 'Naive_Bayes_GS.skmodel')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/Users/neha/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["['Naive_Bayes_GS.skmodel']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"ibbXAF8ISlMf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}